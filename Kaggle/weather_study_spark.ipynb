{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "dir_path = Path().resolve().parent\n",
    "load_dotenv()\n",
    "\n",
    "user = os.getenv('PG_USER')\n",
    "password = os.getenv('PG_PASSWORD')\n",
    "host = os.getenv('PG_HOST', 'localhost')\n",
    "port = os.getenv('PG_PORT', '5432')\n",
    "dbname = os.getenv('POSTGRES_DB')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e8b3a259d49a670d",
   "metadata": {},
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Weather Study\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.2.23\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "url = f\"jdbc:postgresql://{host}:{port}/{dbname}\"\n",
    "properties = {\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5183bc9e9a4b9921",
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, concat_ws, lit, lag, when\n",
    "from pyspark.sql.window import Window"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7c313f0b4320cb7b",
   "metadata": {},
   "source": [
    "daily_weather_query = \"\"\"\n",
    "SELECT \n",
    "    EXTRACT(YEAR FROM dw.date) || '-' || EXTRACT(MONTH FROM dw.date) || '-' || EXTRACT(DAY FROM dw.date) AS \"Date\",\n",
    "    c.name AS \"Location\",\n",
    "    dw.min_temp AS \"MinTemp\",\n",
    "    dw.max_temp AS \"MaxTemp\",\n",
    "    dw.rainfall AS \"Rainfall\",\n",
    "    dw.wind_gust_speed AS \"WindGustSpeed\",\n",
    "    dw.wind_gust_dir AS \"WindGustDir\"\n",
    "FROM \n",
    "    daily_weather dw\n",
    "JOIN \n",
    "    city c ON dw.city_id = c.id\n",
    "ORDER BY \n",
    "    c.name, dw.date\n",
    "\"\"\"\n",
    "\n",
    "df_daily = spark.read.jdbc(url=url, table=f\"({daily_weather_query}) as daily_weather\", properties=properties)\n",
    "\n",
    "df_daily = df_daily.dropDuplicates(['Date', 'Location'])\n",
    "df_daily = df_daily.withColumn(\"Evaporation\", lit(-1)).withColumn(\"Sunshine\", lit(-1))\n",
    "df_daily = df_daily.withColumn(\"RainToday\", when(col(\"Rainfall\") >= 1, \"Yes\").otherwise(\"No\"))\n",
    "\n",
    "window_spec = Window.partitionBy(\"Location\").orderBy(\"Date\")\n",
    "df_daily = df_daily.withColumn(\"RainTomorrow\", lag(\"RainToday\", -1).over(window_spec))\n",
    "df_daily = df_daily.withColumn(\"RainTomorrow\", when(col(\"RainTomorrow\") == \"Yes\", \"Yes\").otherwise(\"No\"))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "weather_9am_query = \"\"\"\n",
    "SELECT \n",
    "    EXTRACT(YEAR FROM w.date) || '-' || EXTRACT(MONTH FROM w.date) || '-' || EXTRACT(DAY FROM w.date) AS \"Date\",\n",
    "    c.name AS \"Location\",\n",
    "    w.temp AS \"Temp9am\",\n",
    "    w.cloudiness AS \"Cloud9am\",\n",
    "    w.pressure AS \"Pressure9am\",\n",
    "    w.humidity AS \"Humidity9am\",\n",
    "    w.wind_gust_speed AS \"WindSpeed9am\",\n",
    "    w.wind_gust_dir AS \"WindDir9am\"\n",
    "FROM \n",
    "    weather w\n",
    "JOIN \n",
    "    city c ON w.city_id = c.id\n",
    "WHERE \n",
    "    EXTRACT(HOUR FROM w.date) = 17\n",
    "ORDER BY \n",
    "    c.name, w.date\n",
    "\"\"\"\n",
    "\n",
    "weather_3pm_query = \"\"\"\n",
    "SELECT \n",
    "    EXTRACT(YEAR FROM w.date) || '-' || EXTRACT(MONTH FROM w.date) || '-' || EXTRACT(DAY FROM w.date) AS \"Date\",\n",
    "    c.name AS \"Location\",\n",
    "    w.temp AS \"Temp3pm\",\n",
    "    w.cloudiness AS \"Cloud3pm\",\n",
    "    w.pressure AS \"Pressure3pm\",\n",
    "    w.humidity AS \"Humidity3pm\",\n",
    "    w.wind_gust_speed AS \"WindSpeed3pm\",\n",
    "    w.wind_gust_dir AS \"WindDir3pm\"\n",
    "FROM \n",
    "    weather w\n",
    "JOIN \n",
    "    city c ON w.city_id = c.id\n",
    "WHERE \n",
    "    EXTRACT(HOUR FROM w.date) = 23\n",
    "ORDER BY \n",
    "    c.name, w.date\n",
    "\"\"\"\n",
    "\n",
    "df_9am = spark.read.jdbc(url=url, table=f\"({weather_9am_query}) as weather_9am\", properties=properties)\n",
    "df_9am = df_9am.dropDuplicates(['Date', 'Location'])\n",
    "\n",
    "df_3pm = spark.read.jdbc(url=url, table=f\"({weather_3pm_query}) as weather_3pm\", properties=properties)\n",
    "df_3pm = df_3pm.dropDuplicates(['Date', 'Location'])"
   ],
   "id": "d6c0ea99dd8799df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_3_9 = df_9am.join(df_3pm, on=['Date', 'Location'], how='inner')",
   "id": "8e88f1f10db1c2a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_open = df_daily.join(df_3_9, on=['Date', 'Location'], how='inner')",
   "id": "9b552920abc677a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "aus_weather_query = \"\"\"\n",
    "SELECT \n",
    "    EXTRACT(YEAR FROM date) || '-' || EXTRACT(MONTH FROM date) || '-' || EXTRACT(DAY FROM date) AS \"Date\",\n",
    "    location AS \"Location\",\n",
    "    min_temp AS \"MinTemp\",\n",
    "    max_temp AS \"MaxTemp\",\n",
    "    rainfall AS \"Rainfall\",\n",
    "    evaporation AS \"Evaporation\",\n",
    "    sunshine AS \"Sunshine\",\n",
    "    wind_gust_dir AS \"WindGustDir\",\n",
    "    wind_gust_speed AS \"WindGustSpeed\",\n",
    "    temp_9am AS \"Temp9am\",\n",
    "    humidity_9am AS \"Humidity9am\",\n",
    "    cloud_9am AS \"Cloud9am\",\n",
    "    wind_dir_9am AS \"WindDir9am\",\n",
    "    wind_speed_9am AS \"WindSpeed9am\",\n",
    "    pressure_9am AS \"Pressure9am\",\n",
    "    temp_3pm AS \"Temp3pm\",\n",
    "    humidity_3pm AS \"Humidity3pm\",\n",
    "    cloud_3pm AS \"Cloud3pm\",\n",
    "    wind_dir_3pm AS \"WindDir3pm\",\n",
    "    wind_speed_3pm AS \"WindSpeed3pm\",\n",
    "    pressure_3pm AS \"Pressure3pm\"\n",
    "FROM \n",
    "    australian_meteorology_weather\n",
    "\"\"\"\n",
    "\n",
    "df_aus = spark.read.jdbc(url=url, table=f\"({aus_weather_query}) as australian_weather\", properties=properties)\n",
    "\n",
    "df_aus = df_aus.withColumn(\"RainToday\", when(col(\"Rainfall\") >= 1, \"Yes\").otherwise(\"No\"))\n",
    "df_aus = df_aus.withColumn(\"RainTomorrow\", lag(\"RainToday\", -1).over(window_spec))\n",
    "df_aus = df_aus.withColumn(\"RainTomorrow\", when(col(\"RainTomorrow\") == \"Yes\", \"Yes\").otherwise(\"No\"))"
   ],
   "id": "cf66c29b6f220798",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_final = df_open.unionByName(df_aus)",
   "id": "37febf5fab2630ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "parquet_path = os.path.join(dir_path, 'dataParquet', 'weather_study.parquet')\n",
    "df_final.write.parquet(parquet_path)"
   ],
   "id": "54ba40c73e511e27",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
