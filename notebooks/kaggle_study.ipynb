{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import joblib\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "82b0cf95d682f647",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set up the root path for the project\n",
    "root_path: Path = Path().resolve().parent"
   ],
   "id": "b3ede8bf12d263f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the configuration file\n",
    "config_path: str = os.path.join(root_path, 'config.json')\n",
    "with open(config_path, 'r') as config_file:\n",
    "    config: Dict[str, Any] = json.load(config_file)"
   ],
   "id": "bfe5086955fcaa40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load the weather data from CSV file\n",
    "file_path: str = os.path.join(root_path, 'data', 'csv', 'weatherAUS.csv')\n",
    "df: pd.DataFrame = pd.read_csv(file_path)"
   ],
   "id": "3c70f4380abd2933",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define column renaming dictionary\n",
    "column_rename_dict: Dict[str, str] = {\n",
    "    'Date': 'date',\n",
    "    'Location': 'location',\n",
    "    'MinTemp': 'min_temp',\n",
    "    'MaxTemp': 'max_temp',\n",
    "    'Rainfall': 'rainfall',\n",
    "    'Evaporation': 'evaporation',\n",
    "    'Sunshine': 'sunshine',\n",
    "    'WindGustDir': 'wind_gust_dir',\n",
    "    'WindGustSpeed': 'wind_gust_speed',\n",
    "    'WindDir9am': 'wind_dir_9am',\n",
    "    'WindDir3pm': 'wind_dir_3pm',\n",
    "    'WindSpeed9am': 'wind_speed_9am',\n",
    "    'WindSpeed3pm': 'wind_speed_3pm',\n",
    "    'Humidity9am': 'humidity_9am',\n",
    "    'Humidity3pm': 'humidity_3pm',\n",
    "    'Pressure9am': 'pressure_9am',\n",
    "    'Pressure3pm': 'pressure_3pm',\n",
    "    'Cloud9am': 'cloud_9am',\n",
    "    'Cloud3pm': 'cloud_3pm',\n",
    "    'Temp9am': 'temp_9am',\n",
    "    'Temp3pm': 'temp_3pm',\n",
    "    'RainToday': 'rain_today',\n",
    "    'RainTomorrow': 'rain_tomorrow'\n",
    "}\n",
    "\n",
    "# Rename columns\n",
    "df = df.rename(columns=column_rename_dict)"
   ],
   "id": "fef13ba623b47d70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Filter the DataFrame to include only specific locations\n",
    "locations_of_interest: List[str] = config['locations']\n",
    "df = df[df['location'].isin(locations_of_interest)]"
   ],
   "id": "69486714f082f294",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert 'date' column to datetime format\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ],
   "id": "c7758eb03d7fd428",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ],
   "id": "52c471b5c9a0bce6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display the shape of the DataFrame\n",
    "df.shape"
   ],
   "id": "3d9e6ad6523e2f9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Data Info\n",
    "df.info()"
   ],
   "id": "a81ad52474508c9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Descriptive Statistics\n",
    "df.describe()"
   ],
   "id": "7a803639563a2268",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Missing Values\n",
    "df.isna().sum()"
   ],
   "id": "3885f9e9110ef376",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop rows with missing target values\n",
    "df = df.dropna(subset=['rain_today', 'rain_tomorrow'])"
   ],
   "id": "af0224a6a98f971",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rainfall over Time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['date'], df['rainfall'])\n",
    "plt.title('Rainfall over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Rainfall (mm)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b065d15533b46b5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Distribution of Min and Max Temperatures\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['min_temp'], kde=True, color='blue', alpha=0.5, label='Min Temp')\n",
    "sns.histplot(df['max_temp'], kde=True, color='red', alpha=0.5, label='Max Temp')\n",
    "plt.title('Distribution of Min and Max Temperatures')\n",
    "plt.xlabel('Temperature (Â°C)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "eace9d5ec7f0a932",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Wind Gust Speed by Location\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='location', y='wind_gust_speed', data=df)\n",
    "plt.title('Wind Gust Speed by Location')\n",
    "plt.xlabel('Location')\n",
    "plt.ylabel('Wind Gust Speed (km/h)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6786ccd88f434daf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Correlation Heatmap of Numerical Features\n",
    "corr = df[df.select_dtypes(include=['int64', 'float64']).columns.tolist()].corr()\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', square=True)\n",
    "plt.title('Correlation Heatmap of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "e688bb319b6e40b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_preprocessor(numerical_columns: List[str],\n",
    "                        categorical_columns: List[str]) -> ColumnTransformer:\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_columns),\n",
    "            ('cat', categorical_transformer, categorical_columns),\n",
    "        ])\n",
    "\n",
    "    return preprocessor"
   ],
   "id": "e0218c58e412b5e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_model_pipeline(model: BaseEstimator, preprocessor: ColumnTransformer, \n",
    "                          oversample: bool = False) -> ImbPipeline:\n",
    "    steps = [('preprocessor', preprocessor)]\n",
    "    \n",
    "    if oversample:\n",
    "        steps.append(('sampler', RandomOverSampler(random_state=42)))\n",
    "    \n",
    "    steps.append(('model', model))\n",
    "    \n",
    "    return ImbPipeline(steps)"
   ],
   "id": "2a10b9ae27d6bbcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compare_models(models: Dict[str, BaseEstimator], X: pd.DataFrame, y: pd.Series, \n",
    "                   preprocessor: ColumnTransformer, \n",
    "                   param_grids: Dict[str, Dict[str, Any]],\n",
    "                   n_iter: int = 10,\n",
    "                   cv: int = 5) -> Dict[str, Dict[str, Any]]:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # Without oversampling\n",
    "        pipeline_no_os = create_model_pipeline(model, preprocessor, oversample=False)\n",
    "        search_no_os = RandomizedSearchCV(pipeline_no_os, param_grids[name], n_iter=n_iter, cv=cv, n_jobs=-1, random_state=42, scoring='f1')\n",
    "        search_no_os.fit(X_train, y_train)\n",
    "        \n",
    "        # With oversampling\n",
    "        pipeline_os = create_model_pipeline(model, preprocessor, oversample=True)\n",
    "        search_os = RandomizedSearchCV(pipeline_os, param_grids[name], n_iter=n_iter, cv=cv, n_jobs=-1, random_state=42, scoring='f1')\n",
    "        search_os.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate best models\n",
    "        results[f\"{name} no oversampling\"] = evaluate_model(search_no_os.best_estimator_, X_test, y_test)\n",
    "        results[f\"{name} with oversampling\"] = evaluate_model(search_os.best_estimator_, X_test, y_test)\n",
    "        \n",
    "        # Store best parameters\n",
    "        results[f\"{name} no oversampling\"][\"best_params\"] = search_no_os.best_params_\n",
    "        results[f\"{name} with oversampling\"][\"best_params\"] = search_os.best_params_\n",
    "    \n",
    "    return results"
   ],
   "id": "9149e00e46b6c240",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_model(model: BaseEstimator, X_test: pd.DataFrame, y_test: np.ndarray) -> Dict[str, float]:\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return {\n",
    "        'accuracy': model.score(X_test, y_test),\n",
    "        'precision': classification_report(y_test, y_pred, output_dict=True, zero_division=0)['weighted avg']['precision'],\n",
    "        'recall': classification_report(y_test, y_pred, output_dict=True, zero_division=0)['weighted avg']['recall'],\n",
    "        'f1-score': classification_report(y_test, y_pred, output_dict=True, zero_division=0)['weighted avg']['f1-score'],\n",
    "        'auc-roc': roc_auc_score(y_test, y_pred_proba)\n",
    "    }"
   ],
   "id": "ff26e1f59d8cff61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare data for modeling\n",
    "X: pd.DataFrame = df.drop(['rain_tomorrow', 'date'], axis=1)\n",
    "y: pd.Series = df['rain_tomorrow']"
   ],
   "id": "96b22fb842e8b638",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define column types for preprocessing\n",
    "numerical_columns: List[str] = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_columns: List[str] = X.select_dtypes(include=['object', 'category']).columns.tolist()"
   ],
   "id": "a4e23c852a1ec263",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Display class distribution\n",
    "y.value_counts(normalize=True)"
   ],
   "id": "818f004006eef89b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Encode target variable\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ],
   "id": "7c58dd26fc0560b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define models to compare\n",
    "models: Dict[str, BaseEstimator] = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42)\n",
    "}"
   ],
   "id": "15cfcd5af1bb70ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'model__C': loguniform(1e-5, 100),\n",
    "        'model__penalty': ['l2'],\n",
    "        'model__solver': ['lbfgs'],\n",
    "        'model__max_iter': [1000, 2000, 5000]\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'model__max_depth': [3, 5, 7, 9, None],\n",
    "        'model__min_samples_split': randint(2, 20),\n",
    "        'model__min_samples_leaf': randint(1, 20)\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model__n_estimators': randint(10, 200),\n",
    "        'model__max_depth': [3, 5, 7, 9, None],\n",
    "        'model__min_samples_split': randint(2, 20),\n",
    "        'model__min_samples_leaf': randint(1, 20)\n",
    "    }\n",
    "}"
   ],
   "id": "7f78e95d546a7d32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create preprocessor\n",
    "preprocessor = create_preprocessor(numerical_columns, categorical_columns)"
   ],
   "id": "6c9b49f631c0d296",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results = compare_models(models, X, y, preprocessor, param_grids, n_iter=20, cv=5)",
   "id": "c96453cf7f31e1e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for name, metrics in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        if metric == 'best_params':\n",
    "            print(f\"\\tBest parameters: {value}\")\n",
    "        else:\n",
    "            print(f\"\\t\\t{metric}: {value:.4f}\")"
   ],
   "id": "41c913bdc454ca55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualize model comparison\n",
    "def plot_model_comparison(results: Dict[str, Dict[str, Any]], metric: str = 'f1-score') -> None:\n",
    "    models = list(results.keys())\n",
    "    scores = [results[model][metric] for model in models]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=models, y=scores)\n",
    "    plt.title(f'Model Comparison - {metric}')\n",
    "    plt.ylabel(metric.capitalize())\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_comparison(results)"
   ],
   "id": "5fc57aae00706827",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_model_name = max(results, key=lambda x: results[x]['f1-score'])\n",
    "best_f1_score = results[best_model_name]['f1-score']\n",
    "best_params = results[best_model_name]['best_params']\n",
    "\n",
    "print(f\"Best overall model: {best_model_name}\")\n",
    "print(f\"Best F1-score: {best_f1_score:.4f}\")\n",
    "print(f\"Best parameters: {best_params}\")"
   ],
   "id": "dcb2964cd308fa09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_best_model(best_model_name: str, X: pd.DataFrame, y: pd.Series) -> BaseEstimator:\n",
    "    model_class = type(models[best_model_name.split('_')[0]])\n",
    "    \n",
    "    cleaned_params = {k.replace('model__', ''): v for k, v in best_params.items()}\n",
    "    \n",
    "    best_model = model_class(**cleaned_params)\n",
    "    \n",
    "    if 'with_oversampling' in best_model_name:\n",
    "        pipeline = create_model_pipeline(best_model, preprocessor, oversample=True)\n",
    "    else:\n",
    "        pipeline = create_model_pipeline(best_model, preprocessor, oversample=False)\n",
    "    \n",
    "    pipeline.fit(X, y)\n",
    "    return pipeline\n",
    "\n",
    "best_model_name = max(results, key=lambda x: results[x]['f1-score'])\n",
    "best_params = results[best_model_name]['best_params']\n",
    "best_model = train_best_model(best_model_name, X, y)"
   ],
   "id": "96063860f6fa9468",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_filename = os.path.join(root_path, \"model\", \"best_model.joblib\")\n",
    "joblib.dump(best_model, model_filename)\n",
    "print(f\"Best model saved to {model_filename}\")"
   ],
   "id": "1ac9bc7db96396f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_rain_tomorrow(model: BaseEstimator, input_data: Dict[str, Any], label_encoder: LabelEncoder) -> str:\n",
    "    input_df = pd.DataFrame([input_data])\n",
    "    prediction = model.predict(input_df)\n",
    "    return label_encoder.inverse_transform(prediction)[0]"
   ],
   "id": "f62628bd1b443936",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example input data\n",
    "example_input = {\n",
    "    'location': 'Sydney',\n",
    "    'min_temp': 15.0,\n",
    "    'max_temp': 25.0,\n",
    "    'rainfall': 0.0,\n",
    "    'evaporation': 4.8,\n",
    "    'sunshine': 8.5,\n",
    "    'wind_gust_dir': 'SE',\n",
    "    'wind_gust_speed': 30,\n",
    "    'wind_dir_9am': 'E',\n",
    "    'wind_dir_3pm': 'SE',\n",
    "    'wind_speed_9am': 10,\n",
    "    'wind_speed_3pm': 15,\n",
    "    'humidity_9am': 70,\n",
    "    'humidity_3pm': 55,\n",
    "    'pressure_9am': 1015.0,\n",
    "    'pressure_3pm': 1013.0,\n",
    "    'cloud_9am': 3,\n",
    "    'cloud_3pm': 4,\n",
    "    'temp_9am': 18.0,\n",
    "    'temp_3pm': 23.5,\n",
    "    'rain_today': 'No'\n",
    "}\n",
    "\n",
    "prediction = predict_rain_tomorrow(best_model, example_input, le)\n",
    "print(f\"Rain Tomorrow Prediction: {prediction}\")"
   ],
   "id": "6b78b010150b7696",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
